{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKP5Z0nChak2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pyarrow.parquet as pq\n",
        "import param\n",
        "from typing import Tuple\n",
        "from typing import Callable\n",
        "\n",
        "def log_time(func):\n",
        "  \"\"\"\n",
        "  Decorator to log the execution time of a function.\n",
        "  \"\"\"\n",
        "  def wrapper(*args, **kwargs):\n",
        "    #Capture the start time before the target function is executed.\n",
        "    start_time = time.time()\n",
        "\n",
        "    #Call the target function and store the result.\n",
        "    result = func(*args, **kwargs)\n",
        "\n",
        "    #Capture the end time after the function completes.\n",
        "    end_time = time.time()\n",
        "\n",
        "    #Print the execution time along with the function name.\n",
        "    print(f\"Execution time for {func.__name__}: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "    #Return the result of the target function from the wrapper.\n",
        "    return result\n",
        "  return wrapper\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataConfig(param.Parameterized):\n",
        "    \"\"\"\n",
        "    A class to configure and generate synthetic data.\n",
        "    This class automatically regenerates data when parameters like num_samples, age, height, etc. change.\n",
        "    Here age, height, weight, income, expenditure configs represent mean[0] and standard deviation[1] values.\n",
        "    \"\"\"\n",
        "    random_seed: int = param.Integer(default = 111, bounds = (1, None))\n",
        "    num_samples: int = param.Integer(default=1000, bounds=(1, None))\n",
        "    age: Tuple[float, float] = param.NumericTuple(default=(18.0, 80.0), length=2)\n",
        "    height: Tuple[float, float] = param.NumericTuple(default=(165.0, 10.0), length=2)\n",
        "    weight: Tuple[float, float] = param.NumericTuple(default=(70.0, 15.0), length=2)\n",
        "    income: Tuple[float, float] = param.NumericTuple(default=(50000.0, 15000.0), length=2)\n",
        "    expenditure: Tuple[float, float] = param.NumericTuple(default=(0.6, 0.1), length=2)\n",
        "    gender: str = param.ListSelector(default=['Male', 'Female', 'Other'], objects=['Male', 'Female', 'Other'])\n",
        "    _data: pd.DataFrame = param.DataFrame(default=pd.DataFrame())\n",
        "\n",
        "    def __init__(self, **params):\n",
        "        super().__init__(**params)\n",
        "        self._generate()\n",
        "\n",
        "    @param.depends('random_seed', 'num_samples', 'age', 'height', 'weight', 'income', 'expenditure', 'gender', watch=True)\n",
        "    def _generate(self, *events):\n",
        "        \"\"\"\n",
        "        Generates synthetic data sets based on the provided parameters.\n",
        "        Triggered automatically whenever configuration parameters change.\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"New Data Generated!!!\")\n",
        "\n",
        "        #Generate Synthetic Data using numpy\n",
        "        np.random.seed(self.random_seed)\n",
        "\n",
        "        #Generating ages using randint where self.age[0] is minimum and self.age[1] is maximum (+1 because maximum is exclusive)\n",
        "        ages = np.random.randint(self.age[0], self.age[1] + 1, self.num_samples)\n",
        "\n",
        "        #Generating Heights, Weights, Incomes, and Expenditures using normal distribution where self.attribute[0] is mean and self.attribute[1] is standard deviation\n",
        "        heights = np.random.normal(self.height[0], self.height[1], self.num_samples)\n",
        "        weights = np.random.normal(self.weight[0], self.weight[1], self.num_samples)\n",
        "        incomes = np.random.normal(self.income[0], self.income[1], self.num_samples)\n",
        "        expenditures = incomes * np.random.normal(self.expenditure[0], self.expenditure[1], self.num_samples)\n",
        "\n",
        "        #Generating Genders\n",
        "        genders = np.random.choice(self.gender, self.num_samples)\n",
        "\n",
        "        #Store dataset as a pandas DataFrame in self._data\n",
        "        self._data = pd.DataFrame({\n",
        "            'Age': ages,\n",
        "            'Height': heights,\n",
        "            'Weight': weights,\n",
        "            'Income': incomes,\n",
        "            'Expenditure': expenditures,\n",
        "            'Gender': genders\n",
        "        })\n",
        "\n",
        "    @property\n",
        "    def data(self) -> pd.DataFrame:\n",
        "        \"\"\"Returns the generated dataset as a pandas DataFrame.\"\"\"\n",
        "        return self._data\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.param)"
      ],
      "metadata": {
        "id": "Mu9-eV904TLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedDataAnalyzer:\n",
        "    def __init__(self, config: DataConfig):\n",
        "        \"\"\"\n",
        "        Initialize the AdvancedDataAnalyzer with a DataConfig instance, and initializes a statistics distionary.\n",
        "        Parameters:\n",
        "        config: (DataConfig): An instance of the DataConfig class.\n",
        "        \"\"\"\n",
        "        #Store the passed config object\n",
        "        self.config = config\n",
        "\n",
        "        #Initialize self._data with the config.data from the input DataConfig instance.\n",
        "        self._data = self.config.data\n",
        "\n",
        "        #Initialize an empty dictionary to store calculated statistics\n",
        "        self._statistics = {}\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        \"\"\"Returns the generated dataset as a pandas DataFrame.\"\"\"\n",
        "        return self.config.data\n",
        "\n",
        "    #Use log_time decorator\n",
        "    @log_time\n",
        "    def calculate_statistics(self):\n",
        "        \"\"\" Group the data by the specified column and calculate the mean for each group.\"\"\"\n",
        "        #Mean\n",
        "        self._statistics['mean'] = self._data.mean(numeric_only=True)\n",
        "\n",
        "        #Median\n",
        "        self._statistics['median'] = self._data.median(numeric_only=True)\n",
        "\n",
        "        #Variance\n",
        "        self._statistics['variance'] = self._data.var(numeric_only=True)\n",
        "\n",
        "        #Correlation Matrix\n",
        "        self._statistics['correlation_matrix'] = self._data.corr(numeric_only=True)\n",
        "\n",
        "        #Store these statistics in self._statistics and return the dictionary.\n",
        "        return self._statistics\n",
        "\n",
        "    def group_by_column(self, column: str):\n",
        "        \"\"\"Group the data by the specified column and calculate the mean for each group.\"\"\"\n",
        "        #Check if the column exists in self._data\n",
        "        if column not in self._data.columns:\n",
        "            raise ValueError(f\"Column '{column}' does not exist in the data.\")\n",
        "\n",
        "        #Use groupby() on the specified column and calculate the mean for each group.\n",
        "        grouped_dataframe = self._data.groupby(column).mean()\n",
        "\n",
        "        #Return the resulting grouped DataFrame.\n",
        "        return grouped_dataframe\n",
        "\n",
        "    def apply_function(self, column: str, func: Callable):\n",
        "        \"\"\"Apply a custom function to all values in the specified column and return the modified series.\"\"\"\n",
        "        #Check if the column exists in self._data\n",
        "        if column not in self._data.columns:\n",
        "            raise ValueError(f\"Column '{column}' does not exist in the data.\")\n",
        "\n",
        "        #Use apply() to apply the passed function (func) to the column.\n",
        "        modified_series = self._data[column].apply(func)\n",
        "\n",
        "        #Return the resulting series\n",
        "        return modified_series\n",
        "\n",
        "    def lazy_filter(self, column: str, condition: Callable):\n",
        "        \"\"\"Lazily filter rows that meet a condition in the specified column using a generator.\"\"\"\n",
        "        #Check if the column exists in self._data\n",
        "        if column not in self._data.columns:\n",
        "            raise ValueError(f\"Column '{column}' does not exist in the data.\")\n",
        "\n",
        "        #Iterate through each row of the DataFrame using iterrows().\n",
        "        for _, row in self._data.iterrows():\n",
        "            #Apply the condition to the column.\n",
        "            if condition(row[column]):\n",
        "                #Yield rows that meet the condition.\n",
        "                yield row\n",
        "\n",
        "    def filter_data(self, column: str, condition: Callable):\n",
        "        \"\"\"Filter the data based on a condition applied to a column and return the filtered DataFrame.\"\"\"\n",
        "        #Check if the column exists in self._data\n",
        "        if column not in self._data.columns:\n",
        "            raise ValueError(f\"Column '{column}' does not exist in the data.\")\n",
        "\n",
        "        #Use apply() to apply the condition and filter the rows.\n",
        "        filtered_dataframe = self._data[self._data[column].apply(condition)]\n",
        "\n",
        "        #Return the filtered DataFrame.\n",
        "        return filtered_dataframe\n",
        "\n",
        "    def visualize_relationship(self, column_x: str, column_y: str):\n",
        "        \"\"\"Visualize the relationship between two columns using a scatter plot.\"\"\"\n",
        "        #Check if the columns exist in self._data\n",
        "        if column_x not in self._data.columns or column_y not in self._data.columns:\n",
        "            raise ValueError(f\"Columns '{column_x}' and/or '{column_y}' do not exist in the data.\")\n",
        "\n",
        "        #Use plt.scatter() to create the scatter plot\n",
        "        plt.scatter(self._data[column_x], self._data[column_y])\n",
        "\n",
        "        #Set the x-label, y-label\n",
        "        plt.xlabel(column_x)\n",
        "        plt.ylabel(column_y)\n",
        "\n",
        "        #Call plt.show() to display the plot.\n",
        "        plt.show()\n",
        "\n",
        "    def visualize_distribution(self, column: str):\n",
        "        \"\"\"Plot the distribution of a specified column using a histogram.\"\"\"\n",
        "        #Check if the column exists in self._data\n",
        "        if column not in self._data.columns:\n",
        "            raise ValueError(f\"Column '{column}' does not exist in the data.\")\n",
        "\n",
        "        #Use plt.hist() to plot the histogram.\n",
        "        plt.hist(self._data[column])\n",
        "\n",
        "        #Set the x-label, y-label\n",
        "        plt.xlabel(column)\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "        #Call plt.show() to display the plot.\n",
        "        plt.show()\n",
        "\n",
        "    #Use log_time decorator\n",
        "    @log_time\n",
        "    def save_data(self, format: str, file_path: str, **kwargs):\n",
        "        \"\"\"Save the DataFrame to disk in the specified format (csv, parquet, or npz).\"\"\"\n",
        "        #Check the format (csv, parquet, npz).\n",
        "        if format == 'csv':\n",
        "            #Add the correct file extension to the file_path\n",
        "            file_path += '.csv'\n",
        "\n",
        "            #Save the data using the appropriate pandas or numpy method\n",
        "            self._data.to_csv(file_path, **kwargs)\n",
        "\n",
        "        elif format == 'parquet':\n",
        "            #Add the correct file extension to the file_path\n",
        "            file_path += '.parquet'\n",
        "\n",
        "            #Save the data using the appropriate pandas or numpy method\n",
        "            self._data.to_parquet(file_path, **kwargs)\n",
        "\n",
        "        elif format == 'npz':\n",
        "            #Add the correct file extension to the file_path\n",
        "            file_path += '.npz'\n",
        "\n",
        "            #Save the data using the appropriate pandas or numpy method\n",
        "            np.savez(file_path, self._data.to_numpy())\n",
        "\n",
        "        #If invalid format found\n",
        "        else:\n",
        "            raise ValueError(\"Invalid format. Please use 'csv', 'parquet', or 'npz'.\")\n",
        "\n",
        "        #Print a success message when saving is complete.\n",
        "        print(f\"Data saved successfully to {file_path}.\")"
      ],
      "metadata": {
        "id": "_Pw3HPbmGbOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathlib\n",
        "\n",
        "class TestDataConfig(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        # Initialize DataConfig with default parameters\n",
        "        self.config = DataConfig()\n",
        "\n",
        "    def test_data_generation(self):\n",
        "        # Test if the data is generated correctly\n",
        "        data = self.config.data\n",
        "        self.assertIsInstance(data, pd.DataFrame)\n",
        "        self.assertEqual(len(data), self.config.num_samples)\n",
        "        self.assertIn('Age', data.columns)\n",
        "        self.assertIn('Height', data.columns)\n",
        "        self.assertIn('Weight', data.columns)\n",
        "        self.assertIn('Income', data.columns)\n",
        "        self.assertIn('Expenditure', data.columns)\n",
        "        self.assertIn('Gender', data.columns)\n",
        "\n",
        "    def test_reactive_data_generation(self):\n",
        "        # Change num_samples and check if data regenerates\n",
        "        old_data = self.config.data.copy()\n",
        "        self.config.num_samples = 2000\n",
        "        new_data = self.config.data\n",
        "        self.assertNotEqual(len(old_data), len(new_data))\n",
        "        self.assertEqual(len(new_data), 2000)\n",
        "\n",
        "    def test_data_randomness(self):\n",
        "        # Check if data generation respects random_seed\n",
        "        self.config.random_seed = 123\n",
        "        data1 = self.config.data.copy()\n",
        "        self.config.random_seed = 123\n",
        "        data2 = self.config.data.copy()\n",
        "        pd.testing.assert_frame_equal(data1, data2)\n",
        "\n",
        "\n",
        "class TestAdvancedDataAnalyzer(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        # Initialize DataConfig and AdvancedDataAnalyzer with default parameters\n",
        "        self.config = DataConfig()\n",
        "        self.analyzer = AdvancedDataAnalyzer(self.config)\n",
        "\n",
        "    def test_calculate_statistics(self):\n",
        "        # Test if statistics are calculated correctly\n",
        "        stats = self.analyzer.calculate_statistics()\n",
        "        self.assertIsInstance(stats, dict)\n",
        "        self.assertIn('mean', stats)\n",
        "        self.assertIn('median', stats)\n",
        "        self.assertIn('variance', stats)\n",
        "        self.assertIn('correlation_matrix', stats)\n",
        "\n",
        "    def test_group_by_column(self):\n",
        "        # Test if data is grouped correctly by Gender\n",
        "        grouped_data = self.analyzer.group_by_column('Gender')\n",
        "        self.assertIsInstance(grouped_data, pd.DataFrame)\n",
        "        self.assertIn('Age', grouped_data.columns)\n",
        "\n",
        "    def test_apply_function(self):\n",
        "        # Test applying a custom function to the Income column\n",
        "        increased_income = self.analyzer.apply_function('Income', lambda x: x * 1.1)\n",
        "        self.assertIsInstance(increased_income, pd.Series)\n",
        "        self.assertTrue(np.allclose(increased_income.values, self.config.data['Income'] * 1.1))\n",
        "\n",
        "    def test_filter_data(self):\n",
        "        # Test filtering data where Age > 50\n",
        "        filtered_data = self.analyzer.filter_data('Age', lambda x: x > 50)\n",
        "        self.assertTrue((filtered_data['Age'] > 50).all())\n",
        "\n",
        "    def test_lazy_filter(self):\n",
        "        # Test lazy filtering where Age > 50\n",
        "        filtered_rows = list(self.analyzer.lazy_filter('Age', lambda x: x > 50))\n",
        "        self.assertTrue(all(row['Age'] > 50 for row in filtered_rows))\n",
        "\n",
        "    def test_save_data(self):\n",
        "        #  Test saving data in CSV format by checking file existence using pathlib\n",
        "        file_path = pathlib.Path(\"test_data.csv\")\n",
        "        # Ensure the file does not exist before the test\n",
        "        if file_path.exists():\n",
        "            file_path.unlink()\n",
        "        # Save data in CSV format\n",
        "        self.analyzer.save_data(format='csv', file_path=\"test_data\")\n",
        "\n",
        "        # Check if the file exists\n",
        "        self.assertTrue(file_path.exists())\n",
        "\n",
        "        # Cleanup the file after the test\n",
        "        file_path.unlink()\n",
        "\n",
        "\n",
        "# Run the tests in Jupyter Notebook\n",
        "def run_tests():\n",
        "    suite = unittest.TestLoader().loadTestsFromTestCase(TestDataConfig)\n",
        "    suite.addTests(unittest.TestLoader().loadTestsFromTestCase(TestAdvancedDataAnalyzer))\n",
        "    unittest.TextTestRunner(verbosity=2).run(suite)\n",
        "\n",
        "# Execute tests\n",
        "run_tests()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAmrlN1iKWff",
        "outputId": "a84149ea-811e-4bc2-feaa-c9300e9c17e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_data_generation (__main__.TestDataConfig) ... ok\n",
            "test_data_randomness (__main__.TestDataConfig) ... ok\n",
            "test_reactive_data_generation (__main__.TestDataConfig) ... ok\n",
            "test_apply_function (__main__.TestAdvancedDataAnalyzer) ... ok\n",
            "test_calculate_statistics (__main__.TestAdvancedDataAnalyzer) ... ok\n",
            "test_filter_data (__main__.TestAdvancedDataAnalyzer) ... ok\n",
            "test_group_by_column (__main__.TestAdvancedDataAnalyzer) ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Data Generated!!!\n",
            "New Data Generated!!!\n",
            "New Data Generated!!!\n",
            "New Data Generated!!!\n",
            "New Data Generated!!!\n",
            "New Data Generated!!!\n",
            "New Data Generated!!!\n",
            "Execution time for calculate_statistics: 0.0114 seconds\n",
            "New Data Generated!!!\n",
            "New Data Generated!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ok\n",
            "test_lazy_filter (__main__.TestAdvancedDataAnalyzer) ... ok\n",
            "test_save_data (__main__.TestAdvancedDataAnalyzer) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 9 tests in 0.335s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Data Generated!!!\n",
            "New Data Generated!!!\n",
            "Data saved successfully to test_data.csv.\n",
            "Execution time for save_data: 0.0108 seconds\n"
          ]
        }
      ]
    }
  ]
}